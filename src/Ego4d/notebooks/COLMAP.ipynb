{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39dad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from ego4d.internal.colmap.preprocess import (\n",
    "    ColmapConfig,\n",
    "    produce_colmap_script,\n",
    "    get_colmap_data_dir,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pycolmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5551ee3d",
   "metadata": {},
   "source": [
    "# Generate COLMAP inputs + Validate\n",
    "\n",
    "Pleae generate the configuration as appropriate, and check the visualizations below under \"Validate Configuration\".\n",
    "\n",
    "Once you have generated a validation configuration, you may upload this to S3. Please refer to the \"Upload Configuration\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9002676",
   "metadata": {},
   "source": [
    "## Configure + Generate\n",
    "\n",
    "Please refer to the inline documentation below.\n",
    "\n",
    "Please set `COLMAP_BIN` and `VRS_BIN`. These should be setup before running the notebook, please refer to the [README](https://github.com/facebookresearch/Ego4d/blob/main/ego4d/internal/colmap/README.md#setup-and-installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005286f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLMAP_BIN = None  # supply your COLMAP_BIN path here\n",
    "VRS_BIN = None  # supply your path to VRS here\n",
    "\n",
    "# be sure to use an absolute path\n",
    "OUTPUT_DIR = \"/private/home/miguelmartin/ego4d/ego4d_public/colmap_experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ColmapConfig(\n",
    "    # if using a metadata path, please\n",
    "    # set video_source and take_id to None\n",
    "    # as this will be derived for you\n",
    "    # COMMENT/UNCOMMENT BEGIN\n",
    "    in_metadata_path=\"s3://ego4d-consortium-sharing/internal/egoexo_pilot/unc/T1/metadata.json\",\n",
    "    in_videos=None,\n",
    "    video_source=None,\n",
    "    take_id=None,\n",
    "    \n",
    "    # whether we are taking synchronized exo-centric frames\n",
    "    sync_exo_views=True,\n",
    "    # where is the walkaround in the VRS file\n",
    "    aria_walkthrough_start_sec=None,\n",
    "    aria_walkthrough_end_sec=None,\n",
    "    # COMMENT/UNCOMMENT END\n",
    "\n",
    "\n",
    "    # FOR TESTING ONLY: uncomment the above to use specific paths.\n",
    "    # NOTE: you cannot enable sync_exo_views if you are using specific paths\n",
    "    # COMMENT/UNCOMMENT BEGIN\n",
    "#     in_metadata_path=None,\n",
    "#     video_source=\"penn\",\n",
    "#     take_id=\"0303_Violin_2\",\n",
    "#     in_videos={\n",
    "#         \"aria01\": \"s3://ego4d-penn/data/0303_Violin_2/ego/aria/c2e4b041-4e68-4b75-8338-f8c625429e75.vrs\",\n",
    "#         \"cam01\": \"s3://ego4d-penn/data/0303_Violin_2/exo/gp01/GX010190.MP4\",\n",
    "#         \"cam02\": \"s3://ego4d-penn/data/0303_Violin_2/exo/gp02/GX010175.MP4\",\n",
    "#         \"cam03\": \"s3://ego4d-penn/data/0303_Violin_2/exo/gp03/GX010012.MP4\",\n",
    "#         \"cam04\": \"s3://ego4d-penn/data/0303_Violin_2/exo/gp04/GX010195.MP4\",\n",
    "#         \"mobile\": \"s3://ego4d-penn/data/0303_Violin_2/exo/mobile/GX010020.MP4\",\n",
    "#     },\n",
    "#     sync_exo_views=False,\n",
    "#     aria_walkthrough_start_sec=30.0,\n",
    "#     aria_walkthrough_end_sec=200.0,\n",
    "    # COMMENT/UNCOMMENT END\n",
    "\n",
    "    output_dir=OUTPUT_DIR,  # where to save data\n",
    "\n",
    "    # there are three rot_mode's:\n",
    "    # - 0 => perform no rotation\n",
    "    # - 1 => rotate aria to exo\n",
    "    # - 2 => rotate exo to aria\n",
    "    rot_mode=1,\n",
    "    \n",
    "    # refer to https://colmap.github.io/cameras.html\n",
    "    camera_model=\"OPENCV_FISHEYE\",\n",
    "    \n",
    "    # the inverse of the number of frames per second to sample\n",
    "    # the mobile walkaround and aria walkaround\n",
    "    frame_rate=0.25,\n",
    "    \n",
    "    # specific mobile frames to use\n",
    "    # if None then all frames are considered using `frame_rate`\n",
    "    mobile_frames=None,\n",
    "    \n",
    "    # whether to include the aria walkaround\n",
    "    include_aria=True,\n",
    "    # if aria_use_sync_info is True then aria_last_walkthrough_sec will be assigned \n",
    "    # based off timesync data\n",
    "    aria_use_sync_info=False,\n",
    "    # specific frames for the walkaround \n",
    "    # if not provided will use all frames in aria will be used (subsampled using `frame_rate`)\n",
    "    aria_frames=None,\n",
    "    \n",
    "    # where to sample the exo videos from\n",
    "    exo_from_frame=700,\n",
    "    exo_to_frame=720,\n",
    "    # specific frames for each exo video\n",
    "    # if one is provided below, all must be provided and exo_from_frame/exo_to_frame must be None\n",
    "    exo_frames=None,\n",
    "    \n",
    "    # the name of the configuration (a relative path/directory where all frames and config is saved to)\n",
    "    # if none a name will be automatically constructed from the above configuration\n",
    "    name=None,\n",
    "    \n",
    "    # misc\n",
    "    aria_fps=30,      # aria is assumed to be (approx) 30fps by default\n",
    "    exo_fps=None,     # if none, this will be determined from the video file\n",
    "    mobile_fps=None,  # if none, this will be determined from the video file\n",
    "    run_colmap=False, # whether we want to run colmap after\n",
    "    colmap_bin=COLMAP_BIN, # where colmap is located, if None a default will be provided\n",
    "    vrs_bin=VRS_BIN,       # where vrs is located, if None a default will be provided\n",
    "    download_video_files=True, # whether we stream from S3 or download videos (changeme if timeout occurs)\n",
    "    force_download=False, # if download_video_files is True, force_download will force a re-download of video files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_used = produce_colmap_script(copy.deepcopy(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3a13b",
   "metadata": {},
   "source": [
    "# Validate Configuration\n",
    "\n",
    "The below section visualizes the exo-centric frames. Please verify that there is no occulusions in each frame. If there is an occulusion, such as a QR code, this may cause issues with SfM (COLMAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67321fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = get_colmap_data_dir(config_used)\n",
    "frames_dir = os.path.join(root_dir, \"frames\")\n",
    "exo_img_paths = {\n",
    "    x: [\n",
    "        os.path.join(frames_dir, x, p)\n",
    "        for p in os.listdir(os.path.join(frames_dir, x))\n",
    "    ]\n",
    "    for x in os.listdir(frames_dir)\n",
    "    if x.startswith(\"cam\")\n",
    "}\n",
    "\n",
    "N_frames = max(len(v) for _, v in exo_img_paths.items())\n",
    "N_cams = len(exo_img_paths)\n",
    "sorted_is = sorted(exo_img_paths.items(), key=lambda x: x[0])\n",
    "viz = [\n",
    "    (cam_i, frame_i, name + f\"_frame_{frame_i}\", path)\n",
    "    for cam_i, (name, paths) in enumerate(sorted_is)\n",
    "    for frame_i, path in enumerate(paths)\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(N_cams * 4, N_frames * 4))\n",
    "ax = fig.subplots(N_cams, N_frames)\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0.1)\n",
    "\n",
    "for i, j, name, path in viz:\n",
    "    x = cv2.imread(path)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    h, w = x.shape[0:2]\n",
    "    ax[i][j].set_xticks([], [])\n",
    "    ax[i][j].set_yticks([], [])\n",
    "    ax[i][j].imshow(x)\n",
    "    ax[i][j].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22236b25",
   "metadata": {},
   "source": [
    "# (Optional) Run COLMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location is to be determined, please hold off on uploading for now\n",
    "colmap_dir = get_colmap_data_dir(config_used)\n",
    "\n",
    "# Please run the run_colmap.sh script\n",
    "colmap_script = os.path.join(colmap_dir, \"run_colmap.sh\")\n",
    "assert os.path.exists(colmap_script)\n",
    "print(\"Please run:\")\n",
    "print()\n",
    "print(f\"sh {colmap_script}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a540f1",
   "metadata": {},
   "source": [
    "# Upload Configuration\n",
    "\n",
    "Please upload your configuration to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_to_upload = colmap_dir\n",
    "print(f\"Please upload {dir_to_upload} to s3://<bucket>/<path_to_data>/<capture_uid>/colmap/ via:\")\n",
    "print()\n",
    "print(f\"aws s3 sync {dir_to_upload} <s3_path>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c2475",
   "metadata": {},
   "source": [
    "# Validate COLMAP Ouptuts\n",
    "\n",
    "After COLMAP has finished running, you can validate the outputs of COLMAP by visualizing view transfer of camera centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLMAP_WORKING_DIR = None\n",
    "if COLMAP_WORKING_DIR is None:\n",
    "    print(\"WARN: using config working dir (check that this is correct)\")\n",
    "    COLMAP_WORKING_DIR = get_colmap_data_dir(config)\n",
    "\n",
    "print(f\"Using: {COLMAP_WORKING_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c94b26",
   "metadata": {},
   "source": [
    "## Quantative\n",
    "\n",
    "At the moment, we do not have another method to quantify results other than what COLMAP has produced in it's analysis. Please ensure:\n",
    "\n",
    "1. All cameras are registered\n",
    "2. There is a significant amount of images in the model\n",
    "3. The reproject is relatively low (<= 1-2 pixels)\n",
    "4. There is one model produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_file = os.path.join(COLMAP_WORKING_DIR, \"analysis_0.txt\")\n",
    "\n",
    "all_models_dir = os.path.join(COLMAP_WORKING_DIR, \"colmap_model\")\n",
    "all_models = [os.path.join(all_models_dir, x) for x in os.listdir(all_models_dir)]\n",
    "if len(all_models) > 1:\n",
    "    model_dir = all_models[0]\n",
    "    print(f\"Multiple models were generated ({len(models)}) instead of one.\")\n",
    "elif len(all_models) == 0:\n",
    "    model_dir = None\n",
    "    print(f\"No models produced.\")\n",
    "else:\n",
    "    model_dir = all_models[0]\n",
    "\n",
    "frame_dir = os.path.join(COLMAP_WORKING_DIR, \"frames\")\n",
    "\n",
    "if os.path.exists(analysis_file):\n",
    "    !cat $analysis_file\n",
    "else:\n",
    "    print(\"No analysis file present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7b86e",
   "metadata": {},
   "source": [
    "## Visualize (Qualatative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5425b",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/colmap/colmap/blob/d6f528ab59fd653966e857f8d0c2203212563631/scripts/python/read_write_model.py#L453\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "      [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "       2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "       2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "      [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "       1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "       2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "      [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "       2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "       1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return NxN array\n",
    "# row => camera\n",
    "# col => image\n",
    "def get_camera_centers(\n",
    "    camera_names,\n",
    "    frame_indices,\n",
    "    cam_exts,\n",
    "    recon,\n",
    "    include_mobile_aria_in_exo,\n",
    "):\n",
    "    ms = [\n",
    "        cam_exts[name][frame_idx] \n",
    "        if frame_idx is not None \n",
    "        else None\n",
    "        for name, frame_idx in zip(camera_names, frame_indices)\n",
    "    ]\n",
    "    N = len(ms)\n",
    "\n",
    "    ret = []\n",
    "    for i in range(N):\n",
    "        row = []\n",
    "\n",
    "        m = ms[i]\n",
    "        if m is None:\n",
    "            ret.append(None)\n",
    "            continue\n",
    "        \n",
    "        c = m[\"camera_center\"]\n",
    "        for j in range(N):\n",
    "            if i == j or ms[j] is None:\n",
    "                row.append(None)\n",
    "                continue\n",
    "            if \"cam\" in camera_names[j] and \\\n",
    "                (\"mobile\" in camera_names[i] or \"aria\" in camera_names[i]) and \\\n",
    "                not include_mobile_aria_in_exo:\n",
    "                print(f\"Skipping {camera_names[i]} in {camera_names[j]}\")\n",
    "                row.append(None)\n",
    "                continue\n",
    "\n",
    "            mj = ms[j]\n",
    "            assert mj is not None\n",
    "\n",
    "            j_cam_id = mj[\"cam_id\"]\n",
    "            j_img_id = mj[\"img_id\"]\n",
    "            j_img = recon.images[j_img_id]\n",
    "            row.append(tuple(\n",
    "                x\n",
    "                for x in recon.cameras[j_cam_id].world_to_image(\n",
    "                    j_img.project(c)\n",
    "                )\n",
    "            ))\n",
    "        ret.append(row)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb61ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_all(cam_names, centers, imgs_by_name, thickness=50, color=(255, 0, 0), radius=10, n_cols=2):\n",
    "    N = len(cam_names)\n",
    "    assert N % n_cols == 0\n",
    "    n_rows = N // n_cols\n",
    "    \n",
    "    fig = plt.figure(figsize=(36*n_rows, 36*n_cols))\n",
    "    ax = fig.subplots(n_rows, n_cols)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            i = (n_rows - 1) * row + col\n",
    "            name = cam_names[i]\n",
    "            img_idx, img = copy.deepcopy(imgs_by_name[name])\n",
    "            assert img_idx == i\n",
    "            \n",
    "            cs = [xs[i] if xs is not None else None for xs in centers]\n",
    "            for c in cs:\n",
    "                if c is None:\n",
    "                    continue\n",
    "                img = cv2.circle(img, tuple(int(x) for x in c), radius=radius, color=color, thickness=thickness)\n",
    "\n",
    "            ax_i = row\n",
    "            ax_j = col\n",
    "            ax_to_use = None\n",
    "            if n_cols == 1 and n_rows == 1:\n",
    "                ax_to_use = ax\n",
    "            elif n_cols == 1:\n",
    "                ax_to_use = ax[ax_j]\n",
    "            else:\n",
    "                ax_to_use = ax[ax_i][ax_j]\n",
    "\n",
    "            if img is not None:\n",
    "                ax_to_use.imshow(img)\n",
    "            ax_to_use.set_title(f\"{name}\")\n",
    "            ax_to_use.set_xticks([], [])\n",
    "            ax_to_use.set_yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd94a19",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_db_path = os.path.join(model_dir, \"cameras.txt\")\n",
    "images_db_path = os.path.join(model_dir, \"images.txt\")\n",
    "points3D_db_path = os.path.join(model_dir, \"points3D.txt\")\n",
    "\n",
    "cameras_txt = open(cameras_db_path).readlines()\n",
    "images_txt = open(images_db_path).readlines()\n",
    "p3d_txt = open(points3D_db_path).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images\n",
    "# https://github.com/rawalkhirodkar/ego4dv2/blob/main/tools/calibration/vis_camera_centers.py#L86\n",
    "image_data = [\n",
    "    line.strip().split()\n",
    "    for line in images_txt[4:][0::2]\n",
    "]\n",
    "\n",
    "cam_exts = defaultdict(list)\n",
    "for line in image_data:\n",
    "    image_path = line[-1]\n",
    "    camera_name = image_path.split('/')[0]\n",
    "    image_name = image_path.split('/')[1]\n",
    "    cam_id = line[-2]\n",
    "    img_id = int(line[0])\n",
    "    \n",
    "    qvec = np.asarray([float(element) for element in line[1:5]]) ## QW, QX, QY, QZ\n",
    "    translation = np.asarray([float(element) for element in line[5:8]]) ## TX, TY, TZ\n",
    "    rotmat = qvec2rotmat(qvec=qvec)\n",
    "    colmap_camera_center = -1*np.dot(rotmat.T, translation) ## -R^t * T\n",
    "\n",
    "    exts = {\n",
    "        'camera_center': colmap_camera_center,\n",
    "        'image_name': image_name,\n",
    "        'image_path': os.path.join(frame_dir, camera_name, image_name),\n",
    "        'qvec': qvec,\n",
    "        'translation': translation,\n",
    "        'rotmat': rotmat,\n",
    "        'cam_id': int(cam_id),\n",
    "        'img_id': int(img_id),\n",
    "    }\n",
    "    cam_exts[camera_name].append(exts)\n",
    "\n",
    "cam_exts = dict(cam_exts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = pycolmap.Reconstruction(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752f83b",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e910e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_frame_idx = 0 # changeme\n",
    "mobile_frame_idx = 0 # changeme\n",
    "aria_frame_idx = -1 # changeme\n",
    "inc_mob_aria_in_exo = False # whether we want to visualize mobile and aria points in the exo perspectives\n",
    "\n",
    "cam_names = [\"cam01\", \"cam02\", \"cam03\", \"cam04\", \"mobile\", \"aria01\"]\n",
    "all_frames =  [exo_frame_idx] * 4 + [mobile_frame_idx, aria_frame_idx]\n",
    "assert len(cam_names) == len(all_frames)\n",
    "centers = get_camera_centers(\n",
    "    cam_names,\n",
    "    all_frames,\n",
    "    cam_exts,\n",
    "    recon,\n",
    "    include_mobile_aria_in_exo=inc_mob_aria_in_exo,\n",
    ")\n",
    "imgs_paths = [\n",
    "    (name, cam_exts[name][frame][\"image_path\"] if frame is not None else None)\n",
    "    for name, frame in zip(cam_names, all_frames)\n",
    "]\n",
    "\n",
    "imgs_by_name = {\n",
    "    name: (idx, cv2.cvtColor(\n",
    "        cv2.imread(img_path),\n",
    "        cv2.COLOR_BGR2RGB,\n",
    "    ) if img_path is not None else None)\n",
    "    for idx, (name, img_path) in enumerate(imgs_paths)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa02472",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_all(cam_names, centers, imgs_by_name, n_cols=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colmap_pycolmap",
   "language": "python",
   "name": "colmap_pycolmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
